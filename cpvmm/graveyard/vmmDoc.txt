vmm_main(UINT32 local_apic_id, UINT64 startup_struct_u, UINT64 application_params_struct_u, UINT64 reserved UNUSED)
    cpu_id = (CPU_ID)local_apic_id;
    host_cpu_enable_usage_of_xmm_regs();
    // setup stack
    vmm_stack_caclulate_stack_pointer(startup_struct, cpu_id, &new_stack_pointer)
    input_params.local_apic_id = local_apic_id;
    hw_set_stack_pointer(new_stack_pointer, (main_continue_fn)vmm_main_continue, &input_params);
	vmm_main_continue calls vmm_bsp_proc_main


void vmm_bsp_proc_main(UINT32 local_apic_id, const VMM_STARTUP_STRUCT* startup_struct,
                       const VMM_APPLICATION_PARAMS_STRUCT* application_params_struct)
    g_num_of_cpus = num_of_cpus;
    hw_calibrate_tsc_ticks_per_second();
    // Init the debug port.
    vmm_debug_port_init_params(&startup_struct->debug_params.port);
    // init the LIBC library
    vmm_libc_init();
        calls vm_io_init
    vmm_version_print();
    addr_setup_address_space();
        calls hw_read_address_size()
    // Initialize stack
    vmm_stack_initialize(startup_struct)
    vmm_stacks_get_details(&lowest_stacks_addr, &stacks_size);
    // Initialize Heap
    heap_address = lowest_stacks_addr + stacks_size;
    vmdb_initialize();
    vmm_serial_cli_init();
    application_params_heap = vmm_create_application_params_struct_copy(application_params_struct);
    // Initialize GDT for all cpus
    hw_gdt_setup(num_of_cpus);
    // Load GDT for BSP
    hw_gdt_load(cpu_id);
    // Initialize IDT for all cpus
    isr_setup();
    // Load IDT for BSP
    isr_handling_start();
    // Store information about e820
    e820_abstraction_initialize((const INT15_E820_MEMORY_MAP*)startup_struct->physical_memory_layout_E820)
    mtrrs_abstraction_bsp_initialize()
    // init uVMM image parser
    exec_image_initialize();
    // Initialize Host Memory Manager
    hmm_initialize(startup_struct)
        including ept's
    hmm_set_required_values_to_control_registers();
    new_cr3 = hmm_get_vmm_page_tables(); // PCD and PWT bits will be 0;
    hw_write_cr3(new_cr3);
    fpt_create_32_bit_flat_page_tables_under_4G((UINT64) 4 GIGABYTES - 1 ); 
    init_teardown_lock();
    // BEFORE_VMLAUNCH. Should not fail.
    heap_last_occupied_address = vmm_heap_extend( g_additional_heap_base, 
                                        g_heap_pa_num * PAGE_4KB_SIZE);
    build_extend_heap_hpa_to_hva();
#ifdef PCI_SCAN
    host_pci_initialize();
#endif
    vmcs_hw_init();
    // init CR0/CR4 to the VMX compatible values
    hw_write_cr0(  vmcs_hw_make_compliant_cr0( hw_read_cr0() ) );
    enable_fx_ops();
    hw_write_cr4(  vmcs_hw_make_compliant_cr4( hw_read_cr4() ) );
    clear_policy(&policy);
#ifdef VTLB_IS_SUPPORTED
    set_paging_policy(&policy, ept_is_ept_supported() ? POL_PG_EPT: POL_PG_VTLB);
#else
    set_paging_policy(&policy, POL_PG_EPT);
    vmm_setup_cpu_specific_policies( &policy );
    global_policy_setup(&policy);

    scheduler_init( (UINT16)num_of_cpus );
    host_cpu_manager_init( num_of_cpus );
    guest_manager_init( (UINT16)num_of_cpus, (UINT16)num_of_cpus );
    local_apic_init( (UINT16)num_of_cpus );
    // create VMEXIT-related data
    vmexit_initialize();
    // init current host CPU
    host_cpu_init();
    local_apic_cpu_init();
#ifdef ENABLE_PREEMPTION_TIMER
    vmx_timer_hw_setup();   // called on every CPU
#endif
    initialize_all_guests(num_of_cpus, &(startup_struct->vmm_memory_layout[uvmm_image]), primary_guest_startup,
                          num_of_guests - 1, secondary_guests_array, application_params_heap)
    // should be set only after guests initialized
    vmm_set_state(VMM_STATE_BOOT);
    // get important guest ids
    nmi_owner_guest            = guest_handle_by_magic_number(startup_struct->nmi_owner);
    acpi_owner_guest           = guest_handle_by_magic_number(startup_struct->acpi_owner);
    device_default_owner_guest = guest_handle_by_magic_number(startup_struct->default_device_owner);
    // BEFORE_VMLAUNCH. PARANOID check as we have only one guest.
    guest_set_nmi_owner(nmi_owner_guest);
    guest_set_acpi_owner(acpi_owner_guest);
    guest_set_default_device_owner(device_default_owner_guest);
    // Initialize Event Manager
    event_manager_initialize(num_of_cpus);
#ifdef PCI_SCAN
    gpci_initialize();
#endif
    // init IPC engine
    nmi_manager_initialize(num_of_cpus)
    !gpm_gpa_to_hva(gcpu_get_current_gpm(acpi_owner_guest), 
                            (GPA)(application_params_struct->fadt_gpa), &fadt_hva))
#ifdef ENABLE_VTD
    !gpm_gpa_to_hva(gcpu_get_current_gpm(acpi_owner_guest), (GPA)(application_params_struct->dmar_gpa),
                            &dmar_hva))
#endif
#ifdef USE_ACPI
    vmm_acpi_init(fadt_hva);
#endif
#ifdef ENABLE_VTD
    vtd_initialize( &(startup_struct->vmm_memory_layout[uvmm_image]),application_params_heap, dmar_hva);
#endif //ENABLE_VTD
    // init all addon packages
    start_addons(num_of_cpus, startup_struct_heap, application_params_heap);
    // Destroy startup structures, which reside in heap
    vmm_destroy_startup_struct(startup_struct_heap);
    startup_struct = NULL;
    startup_struct_heap = NULL;
    vmm_destroy_application_params_struct(application_params_heap);
    application_params_struct = NULL;
    application_params_heap = NULL;
    vmcs_hw_allocate_vmxon_regions(num_of_cpus);
    // Initialize guest data
    initialization_data.num_of_cpus = (UINT16) num_of_cpus;
    for (i = 0; i < VMM_MAX_GUESTS_SUPPORTED; i++){
        initialization_data.guest_data[i].guest_id = INVALID_GUEST_ID;
        initialization_data.guest_data[i].primary_guest = FALSE;
    }
    for (guest = guest_first(&guest_ctx), i = 0; guest; guest = guest_next(&guest_ctx), i++) {
        initialization_data.guest_data[i].guest_id = guest_get_id(guest);
        if (guest_is_primary(guest)) {
            initialization_data.guest_data[i].primary_guest = TRUE;
    report_uvmm_event(UVMM_EVENT_INITIALIZATION_BEFORE_APS_STARTED, NULL, NULL, (void *)&initialization_data)
    vmm_set_state(VMM_STATE_WAIT_FOR_APs);
    LAUNCH_APPLICATION_PROCS();
    initialize_host_vmcs_regions(cpu_id);
    vmcs_hw_vmx_on();
    initial_gcpu = scheduler_select_initial_gcpu();
    ipc_change_state_to_active(initial_gcpu);
    vmm_print_test(local_apic_id);
    WAIT_FOR_APPLICATION_PROCS_LAUNCHED_THE_GUEST( num_of_cpus - 1 );
    report_uvmm_event(UVMM_EVENT_INITIALIZATION_AFTER_APS_STARTED, (VMM_IDENTIFICATION_DATA)initial_gcpu, 
            (const GUEST_VCPU*)guest_vcpu(initial_gcpu), (void *)&initialization_data)
    vmm_set_state(VMM_STATE_RUN);
    event_raise(EVENT_GUEST_LAUNCH, initial_gcpu, &local_apic_id);
    // enable unrestricted guest support in early boot
    // make guest state compliant for code execution
    if(is_unrestricted_guest_supported()) {
    make_guest_state_compliant(initial_gcpu);
            unrestricted_guest_enable(initial_gcpu);
    //make_guest_state_compliant(initial_gcpu);
    } else {
        // For non-UG systems enable EPT, if guest is in paging mode
        EM64T_CR0 guest_cr0;
        guest_cr0.Uint64 = gcpu_get_guest_visible_control_reg(initial_gcpu,IA32_CTRL_CR0);
        if (guest_cr0.Bits.PG) {
            enable_ept_during_launch(initial_gcpu);
        }
    }
#ifdef FAST_VIEW_SWITCH
    if(fvs_is_eptp_switching_supported()) {
        fvs_guest_vmfunc_enable(initial_gcpu);
        fvs_vmfunc_vmcs_init(initial_gcpu);     
    }
#endif
    vmcs_store_initial(initial_gcpu, cpu_id);
    gcpu_resume( initial_gcpu );


// The Application Processor main routine
// Should never return!
void vmm_application_procs_main(UINT32 local_apic_id)
    // Load GDT/IDT
    hw_gdt_load(cpu_id);
    isr_handling_start();
    mtrrs_abstraction_ap_initialize())
    // Set new CR3 to VMM page tables
    hmm_set_required_values_to_control_registers();
    new_cr3 = hmm_get_vmm_page_tables();
    hw_write_cr3(new_cr3);
    // init CR0/CR4 to the VMX compatible values
    hw_write_cr0(  vmcs_hw_make_compliant_cr0( hw_read_cr0() ) );
       enable_fx_ops();
    hw_write_cr4(  vmcs_hw_make_compliant_cr4( hw_read_cr4() ) );
    // init current host CPU
    host_cpu_init();
    local_apic_cpu_init();
    vmcs_hw_vmx_on();
    // schedule first gcpu
    initial_gcpu = scheduler_select_initial_gcpu();
    ipc_change_state_to_active( initial_gcpu );
    vmm_print_test(local_apic_id);
    APPLICATION_PROC_LAUNCHING_THE_GUEST();
    event_raise(EVENT_GUEST_LAUNCH, initial_gcpu, &local_apic_id);
    // enable unrestricted guest support in early boot
    if(is_unrestricted_guest_supported()) {
        make_guest_state_compliant(initial_gcpu);
        unrestricted_guest_enable(initial_gcpu);
    //make_guest_state_compliant(initial_gcpu);
    } else {
        // For non-UG systems enable EPT, if guest is in paging mode
        EM64T_CR0 guest_cr0;
        guest_cr0.Uint64 = gcpu_get_guest_visible_control_reg(initial_gcpu,IA32_CTRL_CR0);
        if (guest_cr0.Bits.PG) {
            enable_ept_during_launch(initial_gcpu);
        }
    vmcs_store_initial(initial_gcpu, cpu_id);
    gcpu_resume( initial_gcpu );


cdecl
	Integer values and memory addresses are returned in the EAX register, 
	floating point values in the ST0 x87 register. 
	Registers EAX, ECX, and EDX are caller-saved, and the rest are callee-saved.
	function arguments are pushed on the stack in the reverse order
	Since GCC version 4.5, the stack must be aligned to a 16-byte boundary when calling a function 

int callee(int, int, int);
 
int caller(void)
{
	int ret;
 
	ret = callee(1, 2, 3);
	ret += 5;
	return ret;
}

caller:
	push	ebp
	mov	ebp, esp
	push	3
	push	2
	push	1
	call	callee
	add	esp, 12
	add	eax, 5
        pop     ebp
	ret
syscall
This is similar to cdecl in that arguments are pushed right to left. 
EAX, ECX, and EDX are not preserved. The size of the parameter list in doublewords is passed in AL

pascal
the parameters are pushed on the stack in left-to-right order (opposite of cdecl), 
and the callee is responsible for balancing the stack before return.

stdcall
variation on the Pascal calling convention 
	callee is responsible for cleaning up the stack, 
	the parameters are pushed onto the stack in right-to-left order, 
	as in the _cdecl calling convention. 
	   Registers EAX, ECX, and EDX are designated for use within the function. 
	   Return values are stored in the EAX register.


